{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import random\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import random\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.data = pd.read_csv(csv_file,names=[\"English\",\"Hindi\"],header=None)\n","        \n","    def __getitem__(self, index):\n","        x = self.data.iloc[index][\"English\"]\n","        y = self.data.iloc[index][\"Hindi\"]\n","        return x, y\n","    \n","    def __len__(self):\n","        return len(self.data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data = MyDataset('/kaggle/input/transliteration/hin_train.csv')\n","train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","test_data = MyDataset('/kaggle/input/transliteration/hin_test.csv')\n","test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n","val_data = MyDataset('/kaggle/input/transliteration/hin_valid.csv')\n","val_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["51200\n"]}],"source":["print(len(train_data))\n","ENGLEN=32\n","HINDILEN=32\n","BATCH_SIZE=128\n","englishwords=torch.full((len(train_data), ENGLEN), 2).to(device)\n","hindiwords=torch.full((len(train_data), HINDILEN), 2).to(device)\n","# hindivocab=[chr(i) for i in range(2304, 2432)]\n","# print(hindivocab.sort())\n","# print(hindivocab)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['0', '1', '2', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"]}],"source":["hindivocab=set()\n","englishvocab=set()\n","for x,y in train_data:\n","    for letter in x:\n","        englishvocab.add(letter)\n","    for letter in y:\n","        hindivocab.add(letter)  \n","for x,y in test_data:\n","    for letter in x:\n","        englishvocab.add(letter)\n","    for letter in y:\n","        hindivocab.add(letter)\n","for x,y in test_data:\n","    for letter in x:\n","        englishvocab.add(letter)\n","    for letter in y:\n","        hindivocab.add(letter)\n","hindivocab=list(hindivocab)\n","hindivocab.sort()\n","englishvocab=list(englishvocab)\n","englishvocab.sort()\n","hindivocab.insert(0,'0')#start\n","hindivocab.insert(1,'1') #end\n","hindivocab.insert(2,'2') #pad\n","englishvocab.insert(0,'0')#start\n","englishvocab.insert(1,'1') #end\n","englishvocab.insert(2,'2') #pad\n","print(englishvocab)\n","hindidictc={}\n","englishdictc={}\n","hindidicti={}\n","englishdicti={}\n","for i in range(len(hindivocab)):\n","    hindidicti[i]=hindivocab[i]\n","    hindidictc[hindivocab[i]]=i\n","for i in range(len(englishvocab)):\n","    englishdicti[i]=englishvocab[i]\n","    englishdictc[englishvocab[i]]=i\n","\n","c=0\n","for x,y in train_data:\n","    for i in range(len(x)):\n","        englishwords[c][i]=englishdictc[x[i]]\n","    for i in range(len(y)):\n","        hindiwords[c][i]=hindidictc[y[i]]\n","    hindiwords[c][i+1]=1\n","    c+=1\n","\n","englishwordsval=torch.full((len(val_data), ENGLEN), 2).to(device)\n","hindiwordsval=torch.full((len(val_data), HINDILEN), 2).to(device)\n","c=0\n","for x,y in test_data:\n","    for i in range(len(x)):\n","        englishwordsval[c][i]=englishdictc[x[i]]\n","    for i in range(len(y)):\n","        hindiwordsval[c][i]=hindidictc[y[i]]\n","    hindiwordsval[c][i+1]=1\n","    c+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["68\n"]}],"source":["print(len(hindivocab))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size,hidden_size,embedding_size,num_layers,typecell,dropout,bidirectional):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = nn.Dropout(dropout)\n","        self.num_layers=num_layers\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.bidirectional=bidirectional\n","        self.p=dropout\n","        self.typecell=typecell\n","        if self.typecell==\"gru\":\n","            self.step = nn.GRU(embedding_size, hidden_size,num_layers,dropout=self.p,bidirectional=self.bidirectional)    \n","        if self.typecell==\"lstm\":\n","            self.step = nn.LSTM(embedding_size, hidden_size,num_layers,dropout=self.p,bidirectional=self.bidirectional)\n","        if self.typecell==\"rnn\":\n","            self.step = nn.RNN(embedding_size, hidden_size,num_layers,dropout=self.p,bidirectional=self.bidirectional) \n","\n","    def forward(self, inp, hidden,cell=None):\n","        embedded = self.dropout(self.embedding(inp))\n","        if self.typecell==\"gru\":\n","            output, hidden = self.step(embedded, hidden)   \n","            return output,hidden\n","        if self.typecell==\"rnn\":\n","            output, hidden = self.step(embedded, hidden)   \n","            return output,hidden\n","        if self.typecell==\"lstm\": \n","            output, (hidden,cell) = self.step(embedded, (hidden,cell))\n","            return output, (hidden,cell)\n","\n","    def initHidden(self):\n","        #for bidirection\n","        num_layers=self.num_layers\n","        if self.bidirectional:\n","            num_layers=self.num_layers*2\n","        hidden=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","        if self.typecell==\"lstm\":\n","            cell=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","            return (hidden,cell)        \n","        return hidden\n","\n","\n","    \n","class DecoderRNN(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_layers,output_size,typecell,dropout):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = nn.Dropout(dropout)\n","        self.num_layers=num_layers\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.output_size=output_size\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.Softmax(dim=2)\n","        self.p=dropout\n","        self.typecell=typecell\n","        if self.typecell==\"gru\":\n","            self.step = nn.GRU(embedding_size, hidden_size,num_layers,dropout=self.p)   \n","        if self.typecell==\"rnn\":\n","            self.step = nn.RNN(embedding_size, hidden_size,num_layers,dropout=self.p) \n","        if self.typecell==\"lstm\":\n","            self.step = nn.LSTM(embedding_size, hidden_size,num_layers,dropout=self.p)\n","\n","    def forward(self, inp, hidden,cell=None):\n","        embedded = self.dropout(self.embedding(inp))\n","        if self.typecell==\"gru\":\n","            output, hidden = self.step(embedded, hidden)   \n","            output1=self.out(output)\n","            return output1,hidden\n","        if self.typecell==\"rnn\":\n","            output, hidden = self.step(embedded, hidden)   \n","            output1=self.out(output)\n","            return output1,hidden\n","        if self.typecell==\"lstm\": \n","            output, (hidden,cell) = self.step(embedded,  (hidden,cell))\n","            output1=self.out(output)\n","            return output1, (hidden,cell)\n","\n","    def initHidden(self):\n","        #for bidirection\n","        num_layers=self.num_layers\n","        hidden=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","        if self.typecell==\"lstm\":\n","            cell=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","            return (hidden,cell)        \n","        return hidden \n","            \n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder,hencoder,cell=None):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.hencoder=hencoder\n","        self.cell=cell\n","    def forward(self, inp, target,teacher_force_ratio):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        if self.encoder.typecell==\"lstm\":\n","            p,(hencoder3d,cell)=self.encoder.forward(inp.to(device),self.hencoder,self.cell)\n","        else:\n","            p,hencoder3d=self.encoder.forward(inp.to(device),self.hencoder)\n","        tempdecoder=torch.zeros(self.encoder.num_layers,BATCH_SIZE,hencoder3d.size()[2]).to(device)\n","        tempdecoder[0]=hencoder3d[hencoder3d.size()[0]//2-1]\n","        tempdecoder[1]=hencoder3d[(hencoder3d.size()[0]//2)*2-1]\n","        hdecoder=torch.add(tempdecoder[0],tempdecoder[1])\n","        hdecoder=hdecoder.repeat(self.decoder.num_layers,1,1)\n","        if self.encoder.typecell==\"lstm\":\n","            tempcell=torch.zeros(2,BATCH_SIZE,cell.size()[2]).to(device)\n","            tempcell[0]=hencoder3d[cell.size()[0]//2-1]\n","            tempcell[1]=hencoder3d[(cell.size()[0]//2)*2-1]\n","            cell=torch.add(tempcell[0],tempcell[1])\n","            cell=cell.repeat(self.decoder.num_layers,1,1)\n","#         hencoder4d=hencoder3d.view(hencoder3d.size()[0]//2,hencoder3d.size()[0]//2,hencoder3d.size()[1],hencoder3d.size()[2])\n","#         hdecoder=self.decoder.initHidden()\n","#         for it in range(hencoder3d.size()//2):\n","#             hdecoder[it]=hencoder4d[it].mean(dim=0)\n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        if self.encoder.typecell==\"lstm\":\n","            output,(hdecoder,cell)=self.decoder.forward(x.to(device),hdecoder,cell)\n","        else:\n","            output,hdecoder=self.decoder.forward(x.to(device),hdecoder)\n","        outputs[0]=output\n","        t=1\n","        for i in range(1,HINDILEN):\n","            if random.random() > teacher_force_ratio:\n","                output=self.decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                if self.encoder.typecell==\"lstm\":\n","                    output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","                else:\n","                    output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","#                 output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","                outputs[t]=output\n","                t+=1\n","            else:\n","                nextinp=target[i-1,:].unsqueeze(0)\n","                if self.encoder.typecell==\"lstm\":\n","                    output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","                else:\n","                    output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","#         if random.random() > teacher_force_ratio:\n","#             for i in range(1,HINDILEN):\n","#                 output=self.decoder.softmax(output)\n","#                 nextinp=torch.argmax(output, dim=2)\n","#                 if self.encoder.typecell==\"lstm\":\n","#                     output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","#                 else:\n","#                     output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","# #                 output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","#                 outputs[t]=output\n","#                 t+=1\n","#         else:            \n","#             for i in range(1,HINDILEN):\n","#                 nextinp=target[i-1,:].unsqueeze(0)\n","#                 if self.encoder.typecell==\"lstm\":\n","#                     output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","#                 else:\n","#                     output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","#                 outputs[t]=output\n","#                 t+=1\n","        return outputs\n","        \n","    \n","\n","def train(encoder,decoder,seq2seq):\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n","    criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n","    loss=0\n","    count=0\n","    numbatches=englishwords.shape[0]//BATCH_SIZE\n","    for ep in range(15):\n","        trainloss=0\n","        train_correct=0\n","        for i in range(numbatches):\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","            temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temp=temp.t()\n","            temph=temph.t()\n","            output=seq2seq.forward(temp,temph,0.5)\n","            train_correct+=train_accuracy(output,temph)\n","            output = output[:].reshape(-1, output.shape[2])\n","            tem = temph[:].reshape(-1)\n","            loss=criterion(output,tem)\n","            loss.backward()\n","            trainloss+=loss.item()\n","            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n","            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","        val_correct,cur_loss=accuracy(seq2seq,englishwordsval,hindiwordsval)\n","        print(ep,trainloss/(51200*HINDILEN),cur_loss/(4096*HINDILEN),val_correct,train_correct)\n","\n","def train_accuracy(output,temph):\n","        output=nn.Softmax(dim=2)(output)\n","        output=torch.argmax(output,dim=2)\n","        temph=temph.t()\n","        output=output.t()\n","        correct=0\n","        for i in range(BATCH_SIZE):\n","            if(torch.equal(output[i],temph[i])):\n","                correct+=1\n","        return correct\n","        \n","def accuracy(seq2seq,english,hindi):\n","    numbatches=english.shape[0]//BATCH_SIZE\n","    correct=0\n","    criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n","    loss=0\n","    for i in range(numbatches):\n","        temp=english[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","        temph=hindi[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","        temp=temp.t()\n","        temph=temph.t()\n","        output=seq2seq.forward(temp,temph,0)\n","        o = output[:].reshape(-1, output.shape[2])\n","        tem = temph[:].reshape(-1)\n","        x=criterion(o,tem)\n","        loss+=x.item()\n","        output=nn.Softmax(dim=2)(output)\n","        output=torch.argmax(output,dim=2)\n","        temph=temph.t()\n","        output=output.t()\n","        for i in range(BATCH_SIZE):\n","            if(torch.equal(output[i],temph[i])):\n","                correct+=1\n","\n","    return correct,loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.5310823743976653 5969 608\n","1 0.3353901833668351 10580 927\n","2 0.29768058070912956 11915 968\n","3 0.274017201801762 14529 1121\n","4 0.25678213089704516 14455 1067\n"]}],"source":["encoder=EncoderRNN(len(englishvocab),512,512,3,\"lstm\",0.2,True).to(device)\n","decoder=DecoderRNN(len(hindivocab),512,512,3,len(hindivocab),\"lstm\",0.2).to(device)\n","hencoder,cell=encoder.initHidden()\n","seq2seq=Seq2Seq(encoder,decoder,hencoder,cell)\n","train(encoder,decoder,seq2seq)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def forward( inp, target,teacher_force_ratio=0.5):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        _,hdecoder=encoder.forward(inp.to(device),hencoder)        \n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        output,hdecoder=decoder.forward(x.to(device),hdecoder)\n","        outputs[0]=output\n","        t=1\n","        for i in range(1,HINDILEN):\n","                output=decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                output,hdecoder=decoder.forward(nextinp.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","        return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def forwardbi( inp, target,teacher_force_ratio=0.5):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        _,hencoder3d=encoder.forward(inp.to(device),hencoder)   \n","        tempdecoder=torch.zeros(2,BATCH_SIZE,hencoder3d.size()[2]).to(device)\n","        tempdecoder[0]=hencoder3d[hencoder3d.size()[0]//2-1]\n","        tempdecoder[1]=hencoder3d[(hencoder3d.size()[0]//2)*2-1]\n","        hdecoder=tempdecoder.mean(dim=0)\n","        hdecoder=hdecoder.repeat(decoder.num_layers,1,1)       \n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        output,hdecoder=decoder.forward(x.to(device),hdecoder)\n","        outputs[0]=output\n","        t=1\n","        for i in range(1,HINDILEN):\n","                output=decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                output,hdecoder=decoder.forward(nextinp.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","        return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17597\n"]}],"source":["def accuracy(englishwords,hindiwords):\n","    numbatches=englishwords.shape[0]//BATCH_SIZE\n","    correct=0\n","    for i in range(numbatches):\n","        temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","        temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","        temp=temp.t()\n","        temph=temph.t()\n","        output=forwardbi(temp,temph)\n","        output=nn.Softmax(dim=2)(output)\n","        output=torch.argmax(output,dim=2)\n","        temph=temph.t()\n","        output=output.t()\n","        for i in range(BATCH_SIZE):\n","            if(torch.equal(output[i],temph[i])):\n","                correct+=1\n","        return correct\n","\n","print(correct)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["englishwordsval=torch.full((len(val_data), ENGLEN), 2).to(device)\n","hindiwordsval=torch.full((len(val_data), HINDILEN), 2).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c=0\n","for x,y in test_data:\n","    for i in range(len(x)):\n","        englishwordsval[c][i]=englishdictc[x[i]]\n","    for i in range(len(y)):\n","        hindiwordsval[c][i]=hindidictc[y[i]]\n","    hindiwordsval[c][i+1]=1\n","    c+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1291\n"]}],"source":["numbatches=englishwordsval.shape[0]//BATCH_SIZE\n","correct=0\n","for i in range(numbatches):\n","    temp=englishwordsval[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","    temph=hindiwordsval[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","    temp=temp.t()\n","    temph=temph.t()\n","    output=forwardbi(temp,temph)\n","    output=nn.Softmax(dim=2)(output)\n","    output=torch.argmax(output,dim=2)\n","    temph=temph.t()\n","    output=output.t()\n","    for i in range(BATCH_SIZE):\n","        if(torch.equal(output[i],temph[i])):\n","            correct+=1\n","\n","\n","print(correct)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4095\n"]}],"source":["# 32,128,512\n","# max size,bs,2*layer(1)*hidden"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class Seq2Seq(nn.Module):\n","#     def __init__(self, encoder, decoder,hencoder):\n","#         super(Seq2Seq, self).__init__()\n","#         self.encoder = encoder\n","#         self.decoder = decoder\n","#         self.hencoder=hencoder\n","#     def forward(self, inp, target,teacher_force_ratio=0.5):\n","#         outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","#         p,hencoder3d=self.encoder.forward(inp.to(device),self.hencoder)   \n","#         tempdecoder=torch.zeros(2,BATCH_SIZE,hencoder3d.size()[2]).to(device)\n","#         tempdecoder[0]=hencoder3d[hencoder3d.size()[0]//2-1]\n","#         tempdecoder[1]=hencoder3d[(hencoder3d.size()[0]//2)*2-1]\n","#         hdecoder=tempdecoder.mean(dim=0)\n","#         hdecoder=hdecoder.repeat(self.decoder.num_layers,1,1)\n","#         x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","#         output,hdecoder=self.decoder.forward(x.to(device),hdecoder,p.to(device))\n","# #         print(hdecoder.size())\n","#         outputs[0]=output\n","#         t=1\n","#         if random.random() > teacher_force_ratio:\n","#             for i in range(1,HINDILEN):\n","#                 output=self.decoder.softmax(output)\n","#                 nextinp=torch.argmax(output, dim=2)\n","#                 output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder,p.to(device))\n","#                 outputs[t]=output\n","#                 t+=1\n","#         else:            \n","#             for i in range(1,HINDILEN):\n","#                 nextinp=target[i-1,:].unsqueeze(0)\n","#                 output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder,p.to(device))\n","#                 outputs[t]=output\n","#                 t+=1\n","#         return outputs\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder,hencoder,cell=None):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.hencoder=hencoder\n","        self.cell=cell\n","    def forward(self, inp, target,teacher_force_ratio):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        if self.encoder.typecell==\"lstm\":\n","            p,(hencoder3d,cell)=self.encoder.forward(inp.to(device),self.hencoder,self.cell)\n","        else:\n","            p,hencoder3d=self.encoder.forward(inp.to(device),self.hencoder)\n","        p=torch.split(p,[self.encoder.hidden_size,self.encoder.hidden_size],dim=2)\n","        p=torch.add(p[0],p[1])\n","        tempdecoder=torch.zeros(self.encoder.num_layers,BATCH_SIZE,hencoder3d.size()[2]).to(device)\n","        tempdecoder[0]=hencoder3d[hencoder3d.size()[0]//2-1]\n","        tempdecoder[1]=hencoder3d[(hencoder3d.size()[0]//2)*2-1]\n","        hdecoder=torch.add(tempdecoder[0],tempdecoder[1])\n","        hdecoder=hdecoder.repeat(self.decoder.num_layers,1,1)\n","        if self.encoder.typecell==\"lstm\":\n","            tempcell=torch.zeros(2,BATCH_SIZE,cell.size()[2]).to(device)\n","            tempcell[0]=hencoder3d[cell.size()[0]//2-1]\n","            tempcell[1]=hencoder3d[(cell.size()[0]//2)*2-1]\n","            cell=torch.add(tempcell[0],tempcell[1])\n","            cell=cell.repeat(self.decoder.num_layers,1,1)\n","#         hencoder4d=hencoder3d.view(hencoder3d.size()[0]//2,hencoder3d.size()[0]//2,hencoder3d.size()[1],hencoder3d.size()[2])\n","#         hdecoder=self.decoder.initHidden()\n","#         for it in range(hencoder3d.size()//2):\n","#             hdecoder[it]=hencoder4d[it].mean(dim=0)\n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        if self.encoder.typecell==\"lstm\":\n","            output,(hdecoder,cell)=self.decoder.forward(x.to(device),hdecoder,p.to(device),cell)\n","        else:\n","            output,hdecoder=self.decoder.forward(x.to(device),hdecoder,p.to(device))\n","        outputs[0]=output\n","        t=1\n","        for i in range(1,HINDILEN):\n","            if random.random() > teacher_force_ratio:\n","                output=self.decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                if self.encoder.typecell==\"lstm\":\n","                    output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,p.to(device),cell)\n","                else:\n","                    output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder,p.to(device))\n","#                 output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,cell)\n","                outputs[t]=output\n","                t+=1\n","            else:\n","                nextinp=target[i-1,:].unsqueeze(0)\n","                if self.encoder.typecell==\"lstm\":\n","                    output,(hdecoder,cell)=self.decoder.forward(nextinp.to(device),hdecoder,p.to(device),cell)\n","                else:\n","                    output,hdecoder=self.decoder.forward(nextinp.to(device),p.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","        return outputs\n","        \n","class Attention(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_layers,output_size,typecell,dropout):\n","        super(Attention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = nn.Dropout(0.2)\n","        self.num_layers=num_layers\n","        self.output_size=output_size\n","        self.typecell=typecell\n","        self.p=dropout\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.u=nn.Linear(hidden_size,hidden_size)\n","        self.w=nn.Linear(hidden_size,hidden_size)\n","        self.v=nn.Linear(hidden_size,1)\n","#         self.gru = nn.GRU(2*hidden_size+embedding_size,hidden_size,num_layers,dropout=self.p)\n","        #first param will change if bidir is false\n","        if self.typecell==\"gru\":\n","            self.step = nn.GRU(2*hidden_size+embedding_size, hidden_size,num_layers,dropout=self.p)    \n","        if self.typecell==\"lstm\":\n","            self.step = nn.LSTM(hidden_size+embedding_size, hidden_size,num_layers,dropout=self.p) \n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.Softmax(dim=2)\n","        \n","    def forward(self, inp, hidden,encoder_output,cell=None):\n","        embedded = self.embedding(inp)\n","#         print(encoder_output.size())\n","        u1=self.u(encoder_output)\n","        w1=self.w(hidden[0])\n","#         print(u1.size())\n","        z=nn.ReLU()(u1+w1.resize(1,BATCH_SIZE,self.hidden_size))\n","#         print(z.size())\n","        et=self.v(z)\n","#         et=nn.ReLU()(self.v(torch.cat((hidden_r, encoder_output), dim=2)))\n","        alpha=nn.Softmax(dim=0)(et)\n","#         print(alpha.size(),encoder_output.size())\n","#         ct = torch.sum(alpha * encoder_output, dim=0, keepdim=True)\n","        ct=torch.bmm(alpha.permute(1, 2, 0), encoder_output.permute(1, 0, 2)).permute(1,0,2)\n","#         ct=torch.einsum(\"snk,snl->knl\", alpha, encoder_output)\n","#         print(ct.size())\n","#         ct=torch.bmm(alpha,encoder_output)\n","        ctet=torch.cat((ct,embedded),dim=2)\n","        if self.typecell==\"gru\":\n","            output, hidden = self.step(ctet, hidden)   \n","            output1=self.out(output)\n","            return output1,hidden\n","        if self.typecell==\"lstm\": \n","            output, (hidden,cell) = self.step(ctet,  (hidden,cell))\n","            output1=self.out(output)\n","            return output1, (hidden,cell)\n","#         output1=self.out(output)\n","#         return output1, hidden\n","    \n","    def initHidden(self):\n","        num_layers=self.num_layers\n","        hidden=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","        if self.typecell==\"lstm\":\n","            cell=torch.zeros(num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","            return (hidden,cell)        \n","        return hidden\n","\n","        \n","        \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]},{"data":{"text/plain":["(tensor([[[ 0.0354,  0.3127,  0.2832,  ...,  0.0775,  0.0958,  0.1181],\n","          [-0.0638,  0.3168,  0.3439,  ..., -0.0098,  0.2600,  0.1728],\n","          [ 0.0404,  0.2177,  0.2104,  ...,  0.1613,  0.0616,  0.2749],\n","          ...,\n","          [ 0.0877,  0.2104,  0.3672,  ...,  0.2486, -0.0261,  0.2160],\n","          [-0.0459,  0.2812,  0.1697,  ...,  0.1973,  0.1747,  0.3285],\n","          [ 0.0590,  0.2805,  0.1684,  ...,  0.1164,  0.0374,  0.1961]]],\n","        grad_fn=<ViewBackward0>),\n"," tensor([[[ 0.2258, -0.2521, -0.4574,  ...,  0.1004,  0.2347,  0.2183],\n","          [-0.1059, -0.5455, -0.0390,  ...,  0.0606,  0.2736,  0.3108],\n","          [ 0.2226, -0.4079, -0.3475,  ...,  0.1928,  0.1755,  0.3311],\n","          ...,\n","          [ 0.1606, -0.2324, -0.2096,  ...,  0.0621,  0.2954,  0.0214],\n","          [-0.1228, -0.1411, -0.2231,  ...,  0.2590,  0.2142, -0.1669],\n","          [-0.1208,  0.1471, -0.3834,  ...,  0.0186,  0.2418,  0.1455]]],\n","        grad_fn=<StackBackward0>))"]},"metadata":{},"output_type":"display_data"}],"source":["inp=torch.full((1,BATCH_SIZE),hindidictc['0']).to(torch.int32)\n","hidden=torch.full((1,BATCH_SIZE,256),hindidictc['0']).to(torch.float32)#to be repeated bs times in code\n","encoder_outputs=torch.full((32,BATCH_SIZE,256*2),hindidictc['0']).to(torch.float32)\n","attention=Attention(len(hindivocab),256,256,2,len(hindivocab))\n","attention.forward(inp,hidden,encoder_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0.6984311667829752\n","1 0.431121762804687\n","2 0.3665090965479612\n","3 0.33561007618904115\n","4 0.31535186517983677\n","5 0.295670186560601\n","6 0.2784927454032004\n","7 0.2676304139196873\n","8 0.25241304429247974\n","9 0.2399233009573072\n","10 0.2382461895979941\n","11 0.22860895477235318\n","12 0.22379849020391704\n","13 0.21717242494225503\n","14 0.2138343177642673\n"]}],"source":["encoder=EncoderRNN(len(englishvocab),128,128,2).to(device)\n","decoder=Attention(len(hindivocab),128,128,2,len(hindivocab)).to(device)\n","hencoder=encoder.initHidden()\n","seq2seq=Seq2Seq(encoder,decoder,hencoder)\n","def train():\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n","    criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n","    loss=0\n","    count=0\n","    numbatches=englishwords.shape[0]//BATCH_SIZE\n","    for ep in range(15):\n","        trainloss=0\n","        for i in range(numbatches):\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","            temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temp=temp.t()\n","            temph=temph.t()\n","            output=seq2seq.forward(temp,temph,0.5)\n","            output = output[:].reshape(-1, output.shape[2])\n","            tem = temph[:].reshape(-1)\n","            loss=criterion(output,tem)\n","            loss.backward()\n","            trainloss+=loss.item()\n","            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n","            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","        print(ep,trainloss/(51200*HINDILEN))\n","    \n","\n","train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder=EncoderRNN(len(englishvocab),512,512,3,\"lstm\",0.2,True).to(device)\n","decoder=Attention(len(hindivocab),512,512,3,len(hindivocab),\"lstm\",0.2).to(device)\n","hencoder,cell=encoder.initHidden()\n","seq2seq=Seq2Seq(encoder,decoder,hencoder,cell)\n","train(encoder,decoder,seq2seq)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def forwardbi( inp, target,teacher_force_ratio=0.5):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        p,hencoder3d=encoder.forward(inp.to(device),hencoder)   \n","        tempdecoder=torch.zeros(2,BATCH_SIZE,hencoder3d.size()[2]).to(device)\n","        tempdecoder[0]=hencoder3d[hencoder3d.size()[0]//2-1]\n","        tempdecoder[1]=hencoder3d[(hencoder3d.size()[0]//2)*2-1]\n","        hdecoder=tempdecoder.mean(dim=0)\n","        hdecoder=hdecoder.repeat(decoder.num_layers,1,1)       \n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        output,hdecoder=decoder.forward(x.to(device),hdecoder,p)\n","        outputs[0]=output\n","        t=1\n","        for i in range(1,HINDILEN):\n","                output=decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                output,hdecoder=decoder.forward(nextinp.to(device),hdecoder,p)\n","                outputs[t]=output\n","                t+=1\n","        return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import random\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, csv_file):\n","        self.data = pd.read_csv(csv_file)\n","        \n","    def __getitem__(self, index):\n","        x = self.data.iloc[index,0]\n","        y = self.data.iloc[index,1]\n","        return x, y\n","    \n","    def __len__(self):\n","        return len(self.data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data = MyDataset('/kaggle/input/transliteration/hin_train.csv')\n","train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","test_data = MyDataset('/kaggle/input/transliteration/hin_test.csv')\n","test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n","val_data = MyDataset('/kaggle/input/transliteration/hin_valid.csv')\n","val_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["51199\n"]}],"source":["print(len(train_data))\n","ENGLEN=32\n","HINDILEN=32\n","BATCH_SIZE=256\n","englishwords=torch.full((len(train_data), ENGLEN), 2).to(device)\n","hindiwords=torch.full((len(train_data), HINDILEN), 2).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['0', '1', '2', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"]}],"source":["hindivocab=set()\n","englishvocab=set()\n","for x,y in train_data:\n","    for letter in x:\n","        englishvocab.add(letter)\n","    for letter in y:\n","        hindivocab.add(letter)  \n","        \n","hindivocab=list(hindivocab)\n","hindivocab.sort()\n","englishvocab=list(englishvocab)\n","englishvocab.sort()\n","hindivocab.insert(0,'0')#start\n","hindivocab.insert(1,'1') #end\n","hindivocab.insert(2,'2') #pad\n","englishvocab.insert(0,'0')#start\n","englishvocab.insert(1,'1') #end\n","englishvocab.insert(2,'2') #pad\n","print(englishvocab)\n","hindidictc={}\n","englishdictc={}\n","hindidicti={}\n","englishdicti={}\n","for i in range(len(hindivocab)):\n","    hindidicti[i]=hindivocab[i]\n","    hindidictc[hindivocab[i]]=i\n","for i in range(len(englishvocab)):\n","    englishdicti[i]=englishvocab[i]\n","    englishdictc[englishvocab[i]]=i\n","\n","c=0\n","for x,y in train_data:\n","    for i in range(len(x)):\n","        englishwords[c][i]=englishdictc[x[i]]\n","    for i in range(len(y)):\n","        hindiwords[c][i]=hindidictc[y[i]]\n","    hindiwords[c][i+1]=1\n","    c+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["67\n"]}],"source":["print(len(hindivocab))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.024784395671304082\n","0.015222961323161144\n","0.012326647563895676\n","0.011098967183897912\n","0.01042161824352661\n"]}],"source":["# temp=torch.full((32,16), 2).to(device)\n","# temph=torch.full((64, 16), 2).to(device)\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size,hidden_size,embedding_size,num_layers):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = nn.Dropout(0.8)\n","        self.num_layers=num_layers\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.gru = nn.GRU(embedding_size, hidden_size,num_layers,dropout=0.8)\n","\n","    def forward(self, inp, hidden):\n","        embedded = self.dropout(self.embedding(inp))\n","        output, hidden = self.gru(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(self.num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","\n","    \n","class DecoderRNN(nn.Module):\n","    def __init__(self,input_size,hidden_size,embedding_size,num_layers,output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.dropout = nn.Dropout(0.8)\n","        self.num_layers=num_layers\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.gru = nn.GRU(embedding_size,hidden_size,num_layers,dropout=0.8)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.Softmax(dim=2)\n","\n","    def forward(self, inp, hidden):\n","        embedded = self.dropout(self.embedding(inp))\n","        output, hidden = self.gru(embedded, hidden)\n","        output1=self.out(output)\n","#         print(output1)\n","#         output2 =self.softmax(output1)\n","        return output1, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(self.num_layers,BATCH_SIZE,self.hidden_size, device=device)\n","            \n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    def forward(self, inp, target,teacher_force_ratio=0.5):\n","        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n","        hencoder=self.encoder.initHidden()\n","        _,hencoder=self.encoder.forward(inp.to(device),hencoder)        \n","        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n","        output,hdecoder=self.decoder.forward(x.to(device),hencoder)\n","        outputs[0]=output\n","        t=1\n","        teacher_forcing_ratio=0.5\n","        if random.random() < teacher_forcing_ratio:\n","            for i in range(1,HINDILEN):\n","                output=self.decoder.softmax(output)\n","                nextinp=torch.argmax(output, dim=2)\n","                output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","        else:            \n","            for i in range(1,HINDILEN):\n","                nextinp=target[i,:].unsqueeze(0)\n","                output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n","                outputs[t]=output\n","                t+=1\n","        return outputs\n","        \n","    \n","encoder=EncoderRNN(len(englishvocab),256,256,2).to(device)\n","decoder=DecoderRNN(len(hindivocab),256,256,2,len(hindivocab)).to(device)\n","seq2seq=Seq2Seq(encoder,decoder)\n","def train():\n","    encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n","    decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n","    criterion = nn.CrossEntropyLoss()\n","    loss=0\n","    count=0\n","    numbatches=englishwords.shape[0]//BATCH_SIZE\n","    for ep in range(5):\n","        trainloss=0\n","        for i in range(numbatches):\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","            temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","            temp=temp.t()\n","            temph=temph.t()\n","            output=seq2seq.forward(temp,temph)\n","            output = output[:].reshape(-1, output.shape[2])\n","            tem = temph[:].reshape(-1)\n","            loss=criterion(output,tem)\n","            loss.backward()\n","            trainloss+=loss.item()/(BATCH_SIZE*HINDILEN)\n","            torch.nn.utils.clip_grad_norm_(decoder.parameters(),max_norm = 1)\n","            torch.nn.utils.clip_grad_norm_(encoder.parameters(),max_norm = 1)\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","        print(trainloss)\n","    \n","\n","train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["18511\n"]}],"source":["numbatches=englishwords.shape[0]//BATCH_SIZE\n","correct=0\n","for i in range(numbatches):\n","    temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","    temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n","    temp=temp.t()\n","    temph=temph.t()\n","    output=seq2seq.forward(temp,temph)\n","    output=nn.Softmax(dim=2)(output)\n","    output=torch.argmax(output,dim=2)\n","    temph=temph.t()\n","    output=output.t()\n","    for i in range(BATCH_SIZE):\n","        if(torch.equal(output[i],temph[i])):\n","            correct+=1\n","\n","print(correct)\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"embedding(): argument 'indices' (position 2) must be Tensor, not str","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n","\u001b[0;32m/tmp/ipykernel_27/2902298691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[1;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m      3\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m----> 4\u001b[0;31m \u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/948261357.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hidden)\u001b[0m\n","\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 10\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n","\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n","\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n","\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n","\u001b[1;32m    160\u001b[0m         return F.embedding(\n","\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m--> 162\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n","\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n","\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not str"]}],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
