{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport random\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T06:30:29.358172Z","iopub.execute_input":"2023-04-23T06:30:29.358498Z","iopub.status.idle":"2023-04-23T06:30:32.426939Z","shell.execute_reply.started":"2023-04-23T06:30:29.358467Z","shell.execute_reply":"2023-04-23T06:30:32.425089Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, csv_file):\n        self.data = pd.read_csv(csv_file)\n        \n    def __getitem__(self, index):\n        x = self.data.iloc[index,0]\n        y = self.data.iloc[index,1]\n        return x, y\n    \n    def __len__(self):\n        return len(self.data)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:30:47.099474Z","iopub.execute_input":"2023-04-23T06:30:47.100642Z","iopub.status.idle":"2023-04-23T06:30:47.107211Z","shell.execute_reply.started":"2023-04-23T06:30:47.100601Z","shell.execute_reply":"2023-04-23T06:30:47.105941Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = MyDataset('/kaggle/input/transliteration/hin_train.csv')\ntrain_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\ntest_data = MyDataset('/kaggle/input/transliteration/hin_test.csv')\ntest_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\nval_data = MyDataset('/kaggle/input/transliteration/hin_valid.csv')\nval_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:30:50.771433Z","iopub.execute_input":"2023-04-23T06:30:50.772107Z","iopub.status.idle":"2023-04-23T06:30:50.928303Z","shell.execute_reply.started":"2023-04-23T06:30:50.772068Z","shell.execute_reply":"2023-04-23T06:30:50.927307Z"},"editable":false,"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))\nENGLEN=32\nHINDILEN=32\nBATCH_SIZE=1024\nenglishwords=torch.full((len(train_data), ENGLEN), 2).to(device)\nhindiwords=torch.full((len(train_data), HINDILEN), 2).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:30:53.700826Z","iopub.execute_input":"2023-04-23T06:30:53.701279Z","iopub.status.idle":"2023-04-23T06:30:57.359130Z","shell.execute_reply.started":"2023-04-23T06:30:53.701236Z","shell.execute_reply":"2023-04-23T06:30:57.357906Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"51199\n","output_type":"stream"}]},{"cell_type":"code","source":"hindivocab=set()\nenglishvocab=set()\nfor x,y in train_data:\n    for letter in x:\n        englishvocab.add(letter)\n    for letter in y:\n        hindivocab.add(letter)  \n        \nhindivocab=list(hindivocab)\nhindivocab.sort()\nenglishvocab=list(englishvocab)\nenglishvocab.sort()\nhindivocab.insert(0,'0')#start\nhindivocab.insert(1,'1') #end\nhindivocab.insert(2,'2') #pad\nenglishvocab.insert(0,'0')#start\nenglishvocab.insert(1,'1') #end\nenglishvocab.insert(2,'2') #pad\nhindidictc={}\nenglishdictc={}\nhindidicti={}\nenglishdicti={}\nfor i in range(len(hindivocab)):\n    hindidicti[i]=hindivocab[i]\n    hindidictc[hindivocab[i]]=i\nfor i in range(len(englishvocab)):\n    englishdicti[i]=englishvocab[i]\n    englishdictc[englishvocab[i]]=i\n\nc=0\nfor x,y in train_data:\n    for i in range(len(x)):\n        englishwords[c][i]=englishdictc[x[i]]\n    for i in range(len(y)):\n        hindiwords[c][i]=hindidictc[y[i]]\n    hindiwords[c][i+1]=1\n    c+=1","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:31:01.514670Z","iopub.execute_input":"2023-04-23T06:31:01.515699Z","iopub.status.idle":"2023-04-23T06:31:22.294943Z","shell.execute_reply.started":"2023-04-23T06:31:01.515643Z","shell.execute_reply":"2023-04-23T06:31:22.293809Z"},"editable":false,"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# temp=torch.full((32,16), 2).to(device)\n# temph=torch.full((64, 16), 2).to(device)\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size,hidden_size,embedding_size,num_layers):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout = nn.Dropout(0.8)\n        self.num_layers=num_layers\n        #input size is eng vocab size\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.gru = nn.GRU(embedding_size, hidden_size,num_layers,dropout=0.8)\n\n    def forward(self, inp, hidden):\n        embedded = self.dropout(self.embedding(inp))\n        output=embedded\n        output, hidden = self.gru(embedded, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(self.num_layers,BATCH_SIZE,self.hidden_size, device=device)\n\n    \nclass DecoderRNN(nn.Module):\n    def __init__(self,input_size,hidden_size,embedding_size,num_layers,output_size):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.dropout = nn.Dropout(0.8)\n        #input size is hindi vocab size\n        self.num_layers=num_layers\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.gru = nn.GRU(embedding_size,hidden_size,num_layers,dropout=0.8)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, inp, hidden):\n#         inp = inp.unsqueeze(0)\n        embedded = self.dropout(self.embedding(inp))\n        output, hidden = self.gru(embedded, hidden)\n        output1=self.out(output)\n        output2 =self.softmax(output1)\n#         output=output.squeeze(0)\n        return output2, hidden\n\n    def initHidden(self):\n        return torch.zeros(self.num_layers,BATCH_SIZE,self.hidden_size, device=device)\n            \nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n    def forward(self, inp, target,teacher_force_ratio=0.5):\n        outputs = torch.zeros(HINDILEN,BATCH_SIZE ,len(hindivocab)).to(device)\n        hencoder=self.encoder.initHidden()\n        _,hencoder=self.encoder.forward(inp.to(device),hencoder)\n#         for i in range(32):\n#             v=inp[:,i]\n#             v=v.unsqueeze(0)\n#             _,hencoder=self.encoder.forward(v.to(device),hencoder)\n            \n        x=torch.full((1,BATCH_SIZE),hindidictc['0'])\n        output,hdecoder=self.decoder.forward(x.to(device),hencoder)\n        outputs[0]=output\n#         targetind=[hindidictc[target[0]]]\n        t=1\n        teacher_forcing_ratio=0.5\n        if random.random() < teacher_forcing_ratio:\n            for i in range(1,HINDILEN):\n                nextinp=torch.argmax(output, dim=2)\n    #             nextinp=target[i,:].unsqueeze(0)\n                output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n                outputs[t]=output\n                t+=1\n        else:            \n            for i in range(1,HINDILEN):\n#                 nextinp=torch.argmax(output, dim=2)\n                nextinp=target[i,:].unsqueeze(0)\n                output,hdecoder=self.decoder.forward(nextinp.to(device),hdecoder)\n                outputs[t]=output\n                t+=1\n\n        return outputs\n        \n        \ndef train():\n    encoder=EncoderRNN(len(englishvocab),256,128,2).to(device)\n    decoder=DecoderRNN(len(hindivocab),256,128,2,len(hindivocab)).to(device)\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n    seq2seq=Seq2Seq(encoder,decoder)\n    criterion = nn.CrossEntropyLoss()\n    loss=0\n    count=0\n    numbatches=englishwords.shape[0]//BATCH_SIZE\n    for ep in range(100):\n        trainloss=0\n        for i in range(numbatches):\n            temp=englishwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n            temph=hindiwords[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n            temp=temp.t()\n            temph=temph.t()\n            output=seq2seq.forward(temp,temph)\n            output = output[:].reshape(-1, output.shape[2])\n            tem = temph[:].reshape(-1)\n            loss=criterion(output,tem)\n            trainloss+=loss.item()/(BATCH_SIZE*HINDILEN)\n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            loss.backward(retain_graph=True)\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n        print(trainloss)\n\n#     for x,y in train_dataloader:\n#         x=[torch.tensor([englishdictc[c] for c in j]) for j in x]\n#         y=[torch.tensor([englishdictc[c] for c in j]) for j in x]\n#         x=torch.nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=2)\n#         print(x)\n#         count+=1\n#         outputs=seq2seq.forward(x[0],y[0])\n#         loss=criterion(outputs,target.to(device))\n#         if(count%1000==0):\n#             print(loss)\n#         encoder_optimizer.zero_grad()\n#         decoder_optimizer.zero_grad()\n#         loss.backward(retain_graph=True)\n#         encoder_optimizer.step()\n#         decoder_optimizer.step()\n\n       \n        \n\ntrain()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:31:41.269720Z","iopub.execute_input":"2023-04-23T06:31:41.270165Z","iopub.status.idle":"2023-04-23T06:32:59.260466Z","shell.execute_reply.started":"2023-04-23T06:31:41.270131Z","shell.execute_reply":"2023-04-23T06:32:59.258813Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0.006287534968578257\n0.006287535026785918\n0.006287534823059104\n0.006287534968578257\n0.0062875347066437826\n0.006287534590228461\n0.0062875348958186805\n0.006287534473813139\n0.006287534983130172\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/547519113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/547519113.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mtem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtrainloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mHINDILEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-19T14:06:08.027800Z","iopub.execute_input":"2023-04-19T14:06:08.028263Z","iopub.status.idle":"2023-04-19T14:06:08.083588Z","shell.execute_reply.started":"2023-04-19T14:06:08.028221Z","shell.execute_reply":"2023-04-19T14:06:08.081238Z"},"editable":false,"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2902298691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/948261357.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hidden)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m         return F.embedding(\n\u001b[1;32m    161\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not str"],"ename":"TypeError","evalue":"embedding(): argument 'indices' (position 2) must be Tensor, not str","output_type":"error"}]}]}